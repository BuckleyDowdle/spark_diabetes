{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier for Diabetes Data\n",
    "\n",
    "**Buckley Dowdle, Latifa Hasan, Luke Moles, Jae Sung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local') \\\n",
    "    .appName('projectModeling') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "df = spark.read.option('header', True) \\\n",
    "    .csv('2017_data.csv', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ParticipantID: integer (nullable = true)\n",
      " |-- Gender: integer (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Race: integer (nullable = true)\n",
      " |-- Education_Level: string (nullable = true)\n",
      " |-- Household_income: string (nullable = true)\n",
      " |-- Pulse: string (nullable = true)\n",
      " |-- SysBP: string (nullable = true)\n",
      " |-- DiasBP: string (nullable = true)\n",
      " |-- Energy: string (nullable = true)\n",
      " |-- Protein: string (nullable = true)\n",
      " |-- Carbohydrates: string (nullable = true)\n",
      " |-- Total_sugar: string (nullable = true)\n",
      " |-- Fiber: string (nullable = true)\n",
      " |-- Total_fat: string (nullable = true)\n",
      " |-- Sat_fat: string (nullable = true)\n",
      " |-- Monounsat_fat: string (nullable = true)\n",
      " |-- Polyunsat_fat: string (nullable = true)\n",
      " |-- cholesterol: string (nullable = true)\n",
      " |-- Alcohol: string (nullable = true)\n",
      " |-- Weight(kg): string (nullable = true)\n",
      " |-- BMI: string (nullable = true)\n",
      " |-- Waist_Circum: string (nullable = true)\n",
      " |-- Insulin: string (nullable = true)\n",
      " |-- Glucose: string (nullable = true)\n",
      " |-- Avg_Drinks: string (nullable = true)\n",
      " |-- 4-5_Drinks: string (nullable = true)\n",
      " |-- 8+Drinks: string (nullable = true)\n",
      " |-- 12+Drinks: string (nullable = true)\n",
      " |-- 4-5DrinksDaily: string (nullable = true)\n",
      " |-- HighBP: string (nullable = true)\n",
      " |-- HighChol: string (nullable = true)\n",
      " |-- VigWork: string (nullable = true)\n",
      " |-- ModWork: string (nullable = true)\n",
      " |-- Walk_bike: string (nullable = true)\n",
      " |-- VigActivity: string (nullable = true)\n",
      " |-- ModActivity: string (nullable = true)\n",
      " |-- 100Cigs: string (nullable = true)\n",
      " |-- Smoke_Cigs: string (nullable = true)\n",
      " |-- Smoke_Cigar: string (nullable = true)\n",
      " |-- E_cig: string (nullable = true)\n",
      " |-- Smokeless_tobacco: string (nullable = true)\n",
      " |-- Diagnosis: string (nullable = true)\n",
      " |-- Diagnosed_age: string (nullable = true)\n",
      " |-- Prediabetes: string (nullable = true)\n",
      " |-- Diabetes_risk: string (nullable = true)\n",
      " |-- Fam_hist: string (nullable = true)\n",
      " |-- Blood_test: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# examine schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114297"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check counts\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ParticipantID', 'int'),\n",
       " ('Gender', 'int'),\n",
       " ('Age', 'double'),\n",
       " ('Race', 'int'),\n",
       " ('Education_Level', 'string'),\n",
       " ('Household_income', 'string'),\n",
       " ('Pulse', 'string'),\n",
       " ('SysBP', 'string'),\n",
       " ('DiasBP', 'string'),\n",
       " ('Energy', 'string'),\n",
       " ('Protein', 'string'),\n",
       " ('Carbohydrates', 'string'),\n",
       " ('Total_sugar', 'string'),\n",
       " ('Fiber', 'string'),\n",
       " ('Total_fat', 'string'),\n",
       " ('Sat_fat', 'string'),\n",
       " ('Monounsat_fat', 'string'),\n",
       " ('Polyunsat_fat', 'string'),\n",
       " ('cholesterol', 'string'),\n",
       " ('Alcohol', 'string'),\n",
       " ('Weight(kg)', 'string'),\n",
       " ('BMI', 'string'),\n",
       " ('Waist_Circum', 'string'),\n",
       " ('Insulin', 'string'),\n",
       " ('Glucose', 'string'),\n",
       " ('Avg_Drinks', 'string'),\n",
       " ('4-5_Drinks', 'string'),\n",
       " ('8+Drinks', 'string'),\n",
       " ('12+Drinks', 'string'),\n",
       " ('4-5DrinksDaily', 'string'),\n",
       " ('HighBP', 'string'),\n",
       " ('HighChol', 'string'),\n",
       " ('VigWork', 'string'),\n",
       " ('ModWork', 'string'),\n",
       " ('Walk_bike', 'string'),\n",
       " ('VigActivity', 'string'),\n",
       " ('ModActivity', 'string'),\n",
       " ('100Cigs', 'string'),\n",
       " ('Smoke_Cigs', 'string'),\n",
       " ('Smoke_Cigar', 'string'),\n",
       " ('E_cig', 'string'),\n",
       " ('Smokeless_tobacco', 'string'),\n",
       " ('Diagnosis', 'string'),\n",
       " ('Diagnosed_age', 'string'),\n",
       " ('Prediabetes', 'string'),\n",
       " ('Diabetes_risk', 'string'),\n",
       " ('Fam_hist', 'string'),\n",
       " ('Blood_test', 'string')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to fix a lot of these to be ints or floats\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all columns we want\n",
    "cols = ['Diagnosis',\n",
    "        'ParticipantID',\n",
    "       'Gender',\n",
    "       'Age',\n",
    "       'Race',\n",
    "       'Fam_hist',\n",
    "       'Smoke_Cigs',\n",
    "       'Glucose',\n",
    "       'BMI',\n",
    "       'SysBP',\n",
    "       'DiasBP',\n",
    "       'Avg_Drinks']\n",
    "data = df.select(cols)\n",
    "\n",
    "# the ones that need to be floats\n",
    "str_to_float = ['Glucose',\n",
    "               'BMI',\n",
    "               'SysBP',\n",
    "               'DiasBP',\n",
    "               'Avg_Drinks']\n",
    "# convert to floats\n",
    "for col in str_to_float:\n",
    "    data = data.withColumn(col, data[col].cast('float'))\n",
    "    \n",
    "# set gender to 0/1 instead of 1/2\n",
    "data = data.withColumn('Gender', data.Gender - 1)\n",
    "# make diagnosis int\n",
    "data = data.withColumn('Diagnosis', data.Diagnosis.cast('int'))\n",
    "\n",
    "# the columns we need to one hot encode\n",
    "cats = ['Fam_hist',\n",
    "       'Smoke_Cigs',\n",
    "       'Race']\n",
    "\n",
    "# one hot encode\n",
    "# will streamline much of this into pipeline later\n",
    "for col in cats:\n",
    "    indexer = StringIndexer(inputCol=col,\n",
    "                           outputCol=col + '_id')\n",
    "    model = indexer.fit(data)\n",
    "    indexed = model.transform(data)\n",
    "    \n",
    "    encoder = OneHotEncoder(inputCol=col+'_id',\n",
    "                           outputCol=col+'_vec')\n",
    "    data = encoder.transform(indexed)\n",
    "\n",
    "# final columns in our df that we need\n",
    "cols = ['ParticipantID',\n",
    "        'Diagnosis',\n",
    "       'Gender',\n",
    "       'Age',\n",
    "       'Race_vec',\n",
    "       'Fam_hist_vec',\n",
    "       'Smoke_Cigs_vec',\n",
    "       'Glucose',\n",
    "       'BMI',\n",
    "       'SysBP',\n",
    "       'DiasBP',\n",
    "       'Avg_Drinks']\n",
    "data = data.select(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ParticipantID', 'int'),\n",
       " ('Diagnosis', 'int'),\n",
       " ('Gender', 'int'),\n",
       " ('Age', 'double'),\n",
       " ('Race_vec', 'vector'),\n",
       " ('Fam_hist_vec', 'vector'),\n",
       " ('Smoke_Cigs_vec', 'vector'),\n",
       " ('Glucose', 'float'),\n",
       " ('BMI', 'float'),\n",
       " ('SysBP', 'float'),\n",
       " ('DiasBP', 'float'),\n",
       " ('Avg_Drinks', 'float')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check types again\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+------+----+-------------+-------------+--------------+-------+----+-----+------+----------+\n",
      "|ParticipantID|Diagnosis|Gender| Age|     Race_vec| Fam_hist_vec|Smoke_Cigs_vec|Glucose| BMI|SysBP|DiasBP|Avg_Drinks|\n",
      "+-------------+---------+------+----+-------------+-------------+--------------+-------+----+-----+------+----------+\n",
      "|        95771|        2|     1|63.0|(5,[1],[1.0])|(2,[1],[1.0])| (3,[1],[1.0])|   7.94|38.6|138.0|  88.0|       2.0|\n",
      "|        96852|        2|     0|35.0|(5,[2],[1.0])|(2,[0],[1.0])| (3,[1],[1.0])|   5.77|37.5|120.0|  64.0|       1.0|\n",
      "|        97450|        2|     1|27.0|(5,[1],[1.0])|(2,[0],[1.0])| (3,[0],[1.0])|   5.44|43.7| 98.0|  58.0|       2.0|\n",
      "|        98530|        1|     0|60.0|(5,[3],[1.0])|(2,[0],[1.0])| (3,[0],[1.0])|   6.66|33.0|124.0|  68.0|       3.0|\n",
      "|        99989|        2|     1|21.0|(5,[2],[1.0])|(2,[0],[1.0])| (3,[0],[1.0])|   6.22|32.3|102.0|  54.0|       6.0|\n",
      "|       101355|        2|     0|46.0|(5,[1],[1.0])|(2,[0],[1.0])| (3,[0],[1.0])|   6.49|28.0|144.0|  82.0|       4.0|\n",
      "|       101814|        2|     1|26.0|(5,[0],[1.0])|(2,[1],[1.0])| (3,[0],[1.0])|   5.66|65.3|140.0|  80.0|       4.0|\n",
      "|       102078|        2|     0|61.0|(5,[1],[1.0])|(2,[0],[1.0])|     (3,[],[])|   6.77|23.6|132.0|  80.0|       2.0|\n",
      "|        94050|        2|     1|55.0|(5,[0],[1.0])|(2,[0],[1.0])| (3,[0],[1.0])|    5.5|27.3|134.0|  86.0|       2.0|\n",
      "|        96553|        2|     0|58.0|(5,[3],[1.0])|(2,[1],[1.0])| (3,[0],[1.0])|   6.27|28.0|122.0|  80.0|       1.0|\n",
      "+-------------+---------+------+----+-------------+-------------+--------------+-------+----+-----+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check results after dropping nulls\n",
    "data.dropna().dropDuplicates().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1526"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna().dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates, nulls, and id\n",
    "data = data.drop().dropDuplicates().select(cols[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble into feature vectors\n",
    "assembler = VectorAssembler(inputCols=cols[2:], outputCol='features')\n",
    "assembled = assembler.setHandleInvalid('skip') \\\n",
    "    .transform(data) \\\n",
    "    .select(['Diagnosis','features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|Diagnosis|            features|\n",
      "+---------+--------------------+\n",
      "|        2|(17,[0,1,3,8,10,1...|\n",
      "|        2|(17,[1,4,7,10,12,...|\n",
      "|        2|(17,[0,1,3,7,9,12...|\n",
      "|        1|(17,[1,5,7,9,12,1...|\n",
      "|        2|(17,[0,1,4,7,9,12...|\n",
      "+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembled.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test-train split\n",
    "(trainingData, testData) = assembled.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build random forest classifier\n",
    "rf = RandomForestClassifier(labelCol='Diagnosis', featuresCol='features', numTrees=10)\n",
    "model = rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "preds = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+--------------------+----------+\n",
      "|Diagnosis|            features|       rawPrediction|         probability|prediction|\n",
      "+---------+--------------------+--------------------+--------------------+----------+\n",
      "|        2|(17,[0,1,3,7,9,12...|[0.0,0.2202305134...|[0.0,0.0220230513...|       2.0|\n",
      "|        2|(17,[1,3,7,9,12,1...|[0.0,0.5219364556...|[0.0,0.0521936455...|       2.0|\n",
      "|        2|(17,[1,3,7,10,12,...|[0.0,0.7666002659...|[0.0,0.0766600265...|       2.0|\n",
      "|        2|(17,[0,1,2,7,9,12...|[0.0,0.4354191187...|[0.0,0.0435419118...|       2.0|\n",
      "|        2|(17,[1,4,7,9,12,1...|[0.0,0.3941184561...|[0.0,0.0394118456...|       2.0|\n",
      "+---------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8978723404255319"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate for accuracy\n",
    "preds.select(['Diagnosis','prediction']) \\\n",
    "    .rdd \\\n",
    "    .map(lambda x: x[0] == x[1]) \\\n",
    "    .sum() / preds.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RF classifier did reasonably well. In the future we will streamline the data pipeline process, evaluate more metrics, and vary RF parameters. We will also collect data from other years. This should be simple to do, and it will be useful since we had to drop so many duplicates and nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/lmm8fb/ds5559/proj/InitialModeling.ipynb to pdf\n",
      "[NbConvertApp] Writing 42843 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 48252 bytes to /sfs/qumulo/qhome/lmm8fb/ds5559/proj/InitialModeling.pdf\n",
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/lmm8fb/ds5559/proj/eda.ipynb to pdf\n",
      "[NbConvertApp] Writing 45588 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 36899 bytes to /sfs/qumulo/qhome/lmm8fb/ds5559/proj/eda.pdf\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to pdf `pwd`/*.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
