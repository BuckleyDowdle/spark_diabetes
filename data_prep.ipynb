{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import data types\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "from pyspark.ml import Pipeline\n",
    "# set up the session\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"diabetes_classifier\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all data files\n",
    "#pandas is needed to read .xpt files then spark is used to create a dataframe\n",
    "\n",
    "demo = spark.createDataFrame(pd.read_sas(\"DEMO_J.XPT\") \\\n",
    "                             .drop(columns = ['SDDSRVYR', 'RIDSTATR', 'RIDAGEMN',\n",
    "                                           'RIDRETH1', 'RIDEXMON', 'RIDEXAGM', 'DMQMILIZ', 'DMQADFC',\n",
    "                                           'DMDBORN4', 'DMDCITZN', 'DMDYRSUS', 'DMDEDUC3', 'DMDMARTL',\n",
    "                                           'RIDEXPRG', 'SIALANG', 'SIAPROXY', 'SIAINTRP', 'FIALANG', 'FIAPROXY',\n",
    "                                           'FIAINTRP', 'MIALANG', 'MIAPROXY', 'MIAINTRP', 'AIALANGA', 'DMDHHSIZ',\n",
    "                                           'DMDFMSIZ', 'DMDHHSZA', 'DMDHHSZB', 'DMDHHSZE', 'DMDHRGND', 'DMDHRAGZ',\n",
    "                                           'DMDHREDZ', 'DMDHRMAZ', 'DMDHSEDZ', 'WTINT2YR', 'WTMEC2YR', 'SDMVPSU',\n",
    "                                           'SDMVSTRA', 'INDFMIN2', 'INDFMPIR']) \\\n",
    "                             .rename({'SEQN': 'ParticipantID', \n",
    "                                    'RIAGENDR': 'Gender',\n",
    "                                    'RIDAGEYR': 'Age',\n",
    "                                    'RIDRETH3': 'Race',\n",
    "                                    'DMDEDUC2': 'Education_Level',\n",
    "                                    'INDHHIN2': 'Household_income'}, axis = 1))\n",
    "\n",
    "diet_1 = spark.createDataFrame(pd.read_sas(\"DR1IFF_J.XPT\")\\\n",
    "                              .drop(columns = ['WTDRD1', 'WTDR2D', 'DR1ILINE', 'DR1DRSTZ', 'DR1EXMER', 'DRABF',\n",
    "                                               'DRDINT', 'DR1DBIH', 'DR1DAY', 'DR1LANG', 'DR1CCMNM', 'DR1CCMTX',\n",
    "                                               'DR1_020', 'DR1_030Z', 'DR1FS', 'DR1_040Z', 'DR1IFDCD', 'DR1IGRMS',\n",
    "                                               'DR1IATOC', 'DR1IATOA',\n",
    "                                               'DR1IRET', 'DR1IVARA', 'DR1IACAR', 'DR1IBCAR', 'DR1ICRYP', 'DR1ILYCO',\n",
    "                                               'DR1ILZ', 'DR1IVB1', 'DR1IVB2', 'DR1INIAC', 'DR1IVB6', 'DR1IFOLA',\n",
    "                                               'DR1IFA', 'DR1IFF', 'DR1IFDFE', 'DR1ICHL', 'DR1IVB12', 'DR1IB12A',\n",
    "                                               'DR1IVC', 'DR1IVD', 'DR1IVK', 'DR1ICALC', 'DR1IPHOS', 'DR1IMAGN',\n",
    "                                               'DR1IIRON', 'DR1IZINC', 'DR1ICOPP', 'DR1ISODI', 'DR1IPOTA', 'DR1ISELE',\n",
    "                                               'DR1ICAFF', 'DR1ITHEO', 'DR1IMOIS', 'DR1IS040', 'DR1IS060',\n",
    "                                               'DR1IS080', 'DR1IS100', 'DR1IS120', 'DR1IS140', 'DR1IS160', 'DR1IS180',\n",
    "                                               'DR1IM161', 'DR1IM181', 'DR1IM201', 'DR1IM221', 'DR1IP182', 'DR1IP183',\n",
    "                                               'DR1IP184', 'DR1IP204', 'DR1IP205', 'DR1IP225', 'DR1IP226']) \\\n",
    "                               .rename({'SEQN': 'ParticipantID', \n",
    "                                        'DR1IKCAL': 'Energy',\n",
    "                                        'DR1IPROT': 'Protein',\n",
    "                                        'DR1ICARB': 'Carbohydrates',\n",
    "                                        'DR1ISUGR': 'Total_sugar',\n",
    "                                        'DR1IFIBE': 'Fiber',\n",
    "                                        'DR1ITFAT': 'Total_fat',\n",
    "                                        'DR1ISFAT': 'Sat_fat',\n",
    "                                        'DR1IMFAT': 'Monounsat_fat',\n",
    "                                        'DR1IPFAT': 'Polyunsat_fat',\n",
    "                                        'DR1ICHOL': 'cholesterol',\n",
    "                                        'DR1IALCO': 'Alcohol'}, axis = 1))\n",
    "\n",
    "bp = spark.createDataFrame(pd.read_sas(\"BPX_J.XPT\") \\\n",
    "                          .drop(columns = ['PEASCCT1', 'BPXCHR', 'BPAARM', 'BPACSZ', 'BPXPLS',\n",
    "                                           'BPXPTY', 'BPXML1', 'BPXSY1', 'BPXDI1', 'BPAEN1', \n",
    "                                           'BPAEN2', 'BPXSY3', 'BPXDI3', 'BPAEN3', 'BPXSY4', \n",
    "                                           'BPXDI4', 'BPAEN4']) \\\n",
    "                          .rename({'SEQN' : 'ParticipantID', \n",
    "                                    'BPXPULS' : 'Pulse', #regular = 1, irregular = 2\n",
    "                                    'BPXSY2' : 'SysBP',\n",
    "                                    'BPXDI2' : 'DiasBP'}, axis = 1))\n",
    "\n",
    "bm = spark.createDataFrame(pd.read_sas(\"BMX_J.XPT\") \\\n",
    "                          .drop(columns = ['BMDSTATS', 'BMIWT', 'BMXRECUM', 'BMIRECUM', 'BMXHEAD',\n",
    "                                           'BMIHEAD', 'BMXHT', 'BMIHT', 'BMXLEG', 'BMILEG', 'BMXARML',\n",
    "                                           'BMIARML', 'BMXARMC', 'BMIARMC', 'BMIWAIST', 'BMXHIP','BMIHIP']) \\\n",
    "                          .rename({'SEQN': 'ParticipantID',\n",
    "                                    'BMXWT': 'Weight(kg)',\n",
    "                                    'BMXBMI': 'BMI',\n",
    "                                    'BMXWAIST': 'Waist_Circum'}, axis = 1))\n",
    "\n",
    "ins = spark.createDataFrame(pd.read_sas(\"INS_J.XPT\") \\\n",
    "                           .drop(columns = ['WTSAF2YR', 'LBDINSI', 'LBDINLC']) \\\n",
    "                           .rename({'SEQN': 'ParticipantID',\n",
    "                                    'LBXIN': 'Insulin'}, axis = 1))\n",
    "\n",
    "glu = spark.createDataFrame(pd.read_sas(\"GLU_J.XPT\") \\\n",
    "                           .drop(columns = ['WTSAF2YR', 'LBXGLU']) \\\n",
    "                           .rename({'SEQN': 'ParticipantID',\n",
    "                                  'LBDGLUSI':'Glucose'}, axis = 1))\n",
    "\n",
    "alc = spark.createDataFrame(pd.read_sas(\"ALQ_J.XPT\") \\\n",
    "                           .drop(columns = ['ALQ111', 'ALQ121', 'ALQ142', 'ALQ170']) \\\n",
    "                           .rename({'SEQN': 'ParticipantID',\n",
    "                                  'ALQ130':'Avg_Drinks',\n",
    "                                  'ALQ270':'4-5_Drinks',\n",
    "                                  'ALQ280':'8+Drinks',\n",
    "                                  'ALQ290':'12+Drinks',\n",
    "                                  'ALQ151':'4-5DrinksDaily'}, axis = 1))\n",
    "\n",
    "bpq = spark.createDataFrame(pd.read_sas(\"BPQ_J.XPT\") \\\n",
    "                           .drop(columns = ['BPQ030', 'BPD035', 'BPQ040A', 'BPQ050A',\n",
    "                                           'BPQ060', 'BPQ070', 'BPQ090D', 'BPQ100D']) \\\n",
    "                           .rename({'SEQN': 'ParticipantID',\n",
    "                                  'BPQ020': 'HighBP', #1 = Yes, 2 = no\n",
    "                                  'BPQ080': 'HighChol'},axis = 1)).filter('HighBP != 9') #1 = Yes, 2 = No\n",
    "    \n",
    "pa = spark.createDataFrame(pd.read_sas(\"PAQ_J.XPT\") \\\n",
    "                           .drop(columns = ['PAQ610', 'PAD615', 'PAQ625', 'PAD630',\n",
    "                                           'PAQ640', 'PAD645', 'PAQ655', 'PAD660',\n",
    "                                           'PAQ670', 'PAD675', 'PAD680'])\\\n",
    "                          .rename({'SEQN': 'ParticipantID',\n",
    "                                    'PAQ605': 'VigWork',\n",
    "                                    'PAQ620': 'ModWork',\n",
    "                                    'PAQ635': 'Walk_bike',\n",
    "                                    'PAQ650': 'VigActivity',\n",
    "                                    'PAQ665': 'ModActivity'},axis = 1))\n",
    "    \n",
    "diab = spark.createDataFrame(pd.read_sas(\"DIQ_J.XPT\") \\\n",
    "                             .drop(columns = ['DIQ172', 'DIQ175C', 'DIQ175D', 'DIQ175E', 'DIQ175F', 'DIQ175G',\n",
    "                                               'DIQ175H', 'DIQ175I', 'DIQ175J', 'DIQ175K', 'DIQ175L', 'DIQ175M',\n",
    "                                               'DIQ175N', 'DIQ175O', 'DIQ175P', 'DIQ175Q', 'DIQ175R', 'DIQ175S',\n",
    "                                               'DIQ175T', 'DIQ175U', 'DIQ175V', 'DIQ175W', 'DIQ175X',\n",
    "                                               'DIQ050', 'DID060', 'DIQ060U', 'DIQ070', 'DIQ230', 'DIQ240', 'DID250',\n",
    "                                               'DID260', 'DIQ260U', 'DIQ275', 'DIQ280', 'DIQ291', 'DIQ300S', 'DIQ300D',\n",
    "                                               'DID310S', 'DID310D', 'DID320', 'DID330', 'DID341', 'DID350', 'DIQ350U',\n",
    "                                               'DIQ360', 'DIQ080', 'DIQ175B']) \\\n",
    "                            .rename({'SEQN': 'ParticipantID',\n",
    "                                    'DIQ010': 'label', #label \n",
    "                                    'DID040': 'Diagnosed_age',\n",
    "                                    'DIQ160': 'Prediabetes',\n",
    "                                    'DIQ170': 'Diabetes_risk',\n",
    "                                    'DIQ175A': 'Fam_hist',\n",
    "                                    'DIQ180': 'Blood_test'}, #1 = yes, 2 = no\n",
    "                                    axis = 1))\n",
    "\n",
    "diab = diab.na.fill({'Fam_hist': 0})\n",
    "diab = diab.withColumn(\"Fam_hist\", \\\n",
    "             when(diab[\"Fam_hist\"] == 99, 0).otherwise(diab[\"Fam_hist\"]))\n",
    "diab = diab.withColumn(\"Fam_hist\", \\\n",
    "              when(diab[\"Fam_hist\"] == 10, 1).otherwise(diab[\"Fam_hist\"]))\n",
    "diab = diab.where(\"label<4\")\n",
    "\n",
    "smq = spark.createDataFrame(pd.read_sas(\"SMQ_J.XPT\") \\\n",
    "                            .drop(columns = ['SMD030', 'SMQ050Q', 'SMQ050U', 'SMD057',\n",
    "                                           'SMQ078', 'SMD641', 'SMD650', 'SMD093', 'SMDUPCA', 'SMD100BR',\n",
    "                                           'SMD100FL', 'SMD100MN', 'SMD100LN', 'SMD100TR', 'SMD100NI', 'SMD100CO',\n",
    "                                           'SMQ621', 'SMD630', 'SMQ661', 'SMQ665A', 'SMQ665B', 'SMQ665C',\n",
    "                                           'SMQ665D', 'SMQ670', 'SMQ848', 'SMQ852Q', 'SMQ852U', 'SMQ895',\n",
    "                                           'SMQ905', 'SMQ915', 'SMAQUEX2']) \\\n",
    "                           .rename({'SEQN': 'ParticipantID',\n",
    "                                  'SMQ020': '100Cigs',\n",
    "                                  'SMQ040': 'Smoke_Cigs', #1 = Yes, 2 = No\n",
    "                                  'SMQ890': 'Smoke_Cigar',\n",
    "                                  'SMQ900': 'E_cig',\n",
    "                                  'SMQ910': 'Smokeless_tobacco'},axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join all dataframes on participant ID\n",
    "df = demo.join(bp, on=['ParticipantID'], how='left').join(diet_1, on=['ParticipantID'], how='left').join(bm, on=['ParticipantID'], how='left').join(ins, on=['ParticipantID'], how='left') \\\n",
    ".join(glu, on=['ParticipantID'], how='left').join(alc, on=['ParticipantID'], how='left').join(bpq, on=['ParticipantID'], how='left').join(pa, on=['ParticipantID'], how='left') \\\n",
    ".join(smq, on=['ParticipantID'], how='left').join(diab, on=['ParticipantID'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ParticipantID: double (nullable = true)\n",
      " |-- Gender: double (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Race: double (nullable = true)\n",
      " |-- Education_Level: double (nullable = true)\n",
      " |-- Household_income: double (nullable = true)\n",
      " |-- Pulse: double (nullable = true)\n",
      " |-- SysBP: double (nullable = true)\n",
      " |-- DiasBP: double (nullable = true)\n",
      " |-- Energy: double (nullable = true)\n",
      " |-- Protein: double (nullable = true)\n",
      " |-- Carbohydrates: double (nullable = true)\n",
      " |-- Total_sugar: double (nullable = true)\n",
      " |-- Fiber: double (nullable = true)\n",
      " |-- Total_fat: double (nullable = true)\n",
      " |-- Sat_fat: double (nullable = true)\n",
      " |-- Monounsat_fat: double (nullable = true)\n",
      " |-- Polyunsat_fat: double (nullable = true)\n",
      " |-- cholesterol: double (nullable = true)\n",
      " |-- Alcohol: double (nullable = true)\n",
      " |-- Weight(kg): double (nullable = true)\n",
      " |-- BMI: double (nullable = true)\n",
      " |-- Waist_Circum: double (nullable = true)\n",
      " |-- Insulin: double (nullable = true)\n",
      " |-- Glucose: double (nullable = true)\n",
      " |-- Avg_Drinks: double (nullable = true)\n",
      " |-- 4-5_Drinks: double (nullable = true)\n",
      " |-- 8+Drinks: double (nullable = true)\n",
      " |-- 12+Drinks: double (nullable = true)\n",
      " |-- 4-5DrinksDaily: double (nullable = true)\n",
      " |-- HighBP: double (nullable = true)\n",
      " |-- HighChol: double (nullable = true)\n",
      " |-- VigWork: double (nullable = true)\n",
      " |-- ModWork: double (nullable = true)\n",
      " |-- Walk_bike: double (nullable = true)\n",
      " |-- VigActivity: double (nullable = true)\n",
      " |-- ModActivity: double (nullable = true)\n",
      " |-- 100Cigs: double (nullable = true)\n",
      " |-- Smoke_Cigs: double (nullable = true)\n",
      " |-- Smoke_Cigar: double (nullable = true)\n",
      " |-- E_cig: double (nullable = true)\n",
      " |-- Smokeless_tobacco: double (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- Diagnosed_age: double (nullable = true)\n",
      " |-- Prediabetes: double (nullable = true)\n",
      " |-- Diabetes_risk: double (nullable = true)\n",
      " |-- Fam_hist: double (nullable = true)\n",
      " |-- Blood_test: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# examine schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ParticipantID', 'double'),\n",
       " ('Gender', 'double'),\n",
       " ('Age', 'double'),\n",
       " ('Race', 'double'),\n",
       " ('Education_Level', 'double'),\n",
       " ('Household_income', 'double'),\n",
       " ('Pulse', 'double'),\n",
       " ('SysBP', 'double'),\n",
       " ('DiasBP', 'double'),\n",
       " ('Energy', 'double'),\n",
       " ('Protein', 'double'),\n",
       " ('Carbohydrates', 'double'),\n",
       " ('Total_sugar', 'double'),\n",
       " ('Fiber', 'double'),\n",
       " ('Total_fat', 'double'),\n",
       " ('Sat_fat', 'double'),\n",
       " ('Monounsat_fat', 'double'),\n",
       " ('Polyunsat_fat', 'double'),\n",
       " ('cholesterol', 'double'),\n",
       " ('Alcohol', 'double'),\n",
       " ('Weight(kg)', 'double'),\n",
       " ('BMI', 'double'),\n",
       " ('Waist_Circum', 'double'),\n",
       " ('Insulin', 'double'),\n",
       " ('Glucose', 'double'),\n",
       " ('Avg_Drinks', 'double'),\n",
       " ('4-5_Drinks', 'double'),\n",
       " ('8+Drinks', 'double'),\n",
       " ('12+Drinks', 'double'),\n",
       " ('4-5DrinksDaily', 'double'),\n",
       " ('HighBP', 'double'),\n",
       " ('HighChol', 'double'),\n",
       " ('VigWork', 'double'),\n",
       " ('ModWork', 'double'),\n",
       " ('Walk_bike', 'double'),\n",
       " ('VigActivity', 'double'),\n",
       " ('ModActivity', 'double'),\n",
       " ('100Cigs', 'double'),\n",
       " ('Smoke_Cigs', 'double'),\n",
       " ('Smoke_Cigar', 'double'),\n",
       " ('E_cig', 'double'),\n",
       " ('Smokeless_tobacco', 'double'),\n",
       " ('label', 'double'),\n",
       " ('Diagnosed_age', 'double'),\n",
       " ('Prediabetes', 'double'),\n",
       " ('Diabetes_risk', 'double'),\n",
       " ('Fam_hist', 'double'),\n",
       " ('Blood_test', 'double')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to fix a lot of these to be ints or floats\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "df = df.drop().dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all columns we want\n",
    "cols = ['ParticipantID',\n",
    "        'label',\n",
    "       'Gender',\n",
    "       'Age',\n",
    "       'Race',\n",
    "       'Fam_hist',\n",
    "       'Smoke_Cigs',\n",
    "       'BMI',\n",
    "        'HighBP' \n",
    "       ]\n",
    "data = df.select(cols)\n",
    "\n",
    "\n",
    "# set gender to 0/1 instead of 1/2\n",
    "data = data.withColumn('Gender', data.Gender - 1)\n",
    "\n",
    "#drop na values\n",
    "data = data.na.drop('any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27297"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()\n",
    "#data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ParticipantID=94021.0, label=2.0, Gender=1.0, Age=38.0, Race=3.0, Fam_hist=0.0, Smoke_Cigs=3.0, BMI=34.5, HighBP=2.0),\n",
       " Row(ParticipantID=94021.0, label=2.0, Gender=1.0, Age=38.0, Race=3.0, Fam_hist=0.0, Smoke_Cigs=3.0, BMI=34.5, HighBP=2.0),\n",
       " Row(ParticipantID=94021.0, label=2.0, Gender=1.0, Age=38.0, Race=3.0, Fam_hist=0.0, Smoke_Cigs=3.0, BMI=34.5, HighBP=2.0),\n",
       " Row(ParticipantID=94021.0, label=2.0, Gender=1.0, Age=38.0, Race=3.0, Fam_hist=0.0, Smoke_Cigs=3.0, BMI=34.5, HighBP=2.0),\n",
       " Row(ParticipantID=94021.0, label=2.0, Gender=1.0, Age=38.0, Race=3.0, Fam_hist=0.0, Smoke_Cigs=3.0, BMI=34.5, HighBP=2.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.write.parquet(\"data.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
